{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59eef5a4",
   "metadata": {},
   "source": [
    "# STA130 HW 1 pre-class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f3709f",
   "metadata": {},
   "source": [
    "### self session 1: https://chatgpt.com/share/69fa897b-1eed-4ba5-b99b-455e46f84157"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aac818c",
   "metadata": {},
   "source": [
    "#### summery of self session 1\n",
    "\n",
    "In our interaction, we explored various amusing and interesting datasets, specifically looking for those with missing values. I guided you through the process of finding datasets by searching relevant sources, leading to the selection of a **Diabetes Missing Data** dataset from GitHub.\n",
    "\n",
    "Next, I provided a Python code snippet using the `pandas` library, which can be used to count missing values in the dataset. The code loads the dataset from the URL, checks for missing values using the `isnull()` function, and displays the count for each column.\n",
    "\n",
    "Additionally, I shared a few other datasets you could explore for different use cases, including those related to jokes, Bigfoot sightings, and a squirrel census.\n",
    "\n",
    "This summary encapsulates our discussion about finding an interesting dataset with missing values and creating a Python solution to analyze it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0701f0",
   "metadata": {},
   "source": [
    "#### 1. picking the dataset\n",
    "    the dataset is in the following code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57fccd76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values count per column:\n",
      "Pregnant               0\n",
      "Glucose                5\n",
      "Diastolic_BP          35\n",
      "Skin_Fold            227\n",
      "Serum_Insulin        374\n",
      "BMI                   11\n",
      "Diabetes_Pedigree      0\n",
      "Age                    0\n",
      "Class                  0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset from the CSV file\n",
    "url = \"https://github.com/YBI-Foundation/Dataset/raw/main/Diabetes%20Missing%20Data.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Display the count of missing values in each column\n",
    "missing_values = df.isnull().sum()\n",
    "print(\"Missing values count per column:\")\n",
    "print(missing_values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e548cffc",
   "metadata": {},
   "source": [
    "### self session 2  https://chatgpt.com/share/6ceb1038-f820-463d-9536-72e1f590377d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4680bc69",
   "metadata": {},
   "source": [
    "#### summery of self session 2\n",
    "\n",
    "Here’s a summary of our interaction for your assignment submission:\n",
    "\n",
    "---\n",
    "\n",
    "### **Summary of Interaction with ChatGPT**\n",
    "\n",
    "In this session, I worked with ChatGPT to analyze and explore a dataset related to diabetes, covering key steps in data analysis and basic concepts in object-oriented programming.\n",
    "\n",
    "1. **Dataset Analysis**:\n",
    "   - I uploaded a dataset named \"Diabetes Missing Data.csv.\"\n",
    "   - ChatGPT helped me determine that the dataset contains **768 rows** (observations) and **9 columns** (variables).\n",
    "   - I requested a Python code snippet for finding the number of rows and columns in a dataset, which ChatGPT provided:\n",
    "     ```python\n",
    "     import pandas as pd\n",
    "     data = pd.read_csv('path_to_your_dataset.csv')\n",
    "     rows, columns = data.shape\n",
    "     print(f\"The dataset has {rows} rows and {columns} columns.\")\n",
    "     ```\n",
    "\n",
    "2. **Explanation of Observations and Variables**:\n",
    "   - ChatGPT explained the definitions of **observations** (rows) and **variables** (columns). \n",
    "   - Observations are individual data points, while variables are the attributes of each observation.\n",
    "   - In the diabetes dataset, each row represents an observation (e.g., one patient’s data), and each column is a variable (e.g., \"Glucose\", \"Age\").\n",
    "\n",
    "3. **Generating Summaries of Dataset Columns**:\n",
    "   - I asked ChatGPT how to provide a summary of the dataset's columns. \n",
    "   - It provided a Python code to generate statistical summaries using the `describe()` function in pandas, offering insights into the dataset's numeric columns (mean, standard deviation, min, max, etc.).\n",
    "\n",
    "4. **Explanation of Attributes vs Methods**:\n",
    "   - ChatGPT explained the difference between **attributes** and **methods**:\n",
    "     - An **attribute** is a property that holds data about an object (e.g., `data.shape` for a DataFrame).\n",
    "     - A **method** is a function that performs an operation on an object (e.g., `data.describe()`).\n",
    "\n",
    "This interaction deepened my understanding of basic data analysis, dataset structures, and object-oriented programming concepts in Python. \n",
    "\n",
    "--- \n",
    "\n",
    "This summary captures the main points of our discussion and includes relevant code examples that were discussed during the session."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5667ec",
   "metadata": {},
   "source": [
    "#### 2. finding the number of the rows and the columns in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b2dacac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset has 768 rows and 9 columns.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'https://github.com/YBI-Foundation/Dataset/raw/main/Diabetes%20Missing%20Data.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Get the number of rows and columns\n",
    "rows, columns = data.shape\n",
    "\n",
    "print(f\"The dataset has {rows} rows and {columns} columns.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06d6fd5",
   "metadata": {},
   "source": [
    "Definitions:\n",
    "\n",
    "    Observations: an individual data in a statistical research is called an observation\n",
    "    Variables: the attributes or aspects collected for a statistical research is called variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf72b39a",
   "metadata": {},
   "source": [
    "#### 3. provide summary using python code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a75b48a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Pregnant     Glucose  Diastolic_BP   Skin_Fold  Serum_Insulin  \\\n",
      "count  768.000000  763.000000    733.000000  541.000000     394.000000   \n",
      "mean     3.845052  121.686763     72.405184   29.153420     155.548223   \n",
      "std      3.369578   30.535641     12.382158   10.476982     118.775855   \n",
      "min      0.000000   44.000000     24.000000    7.000000      14.000000   \n",
      "25%      1.000000   99.000000     64.000000   22.000000      76.250000   \n",
      "50%      3.000000  117.000000     72.000000   29.000000     125.000000   \n",
      "75%      6.000000  141.000000     80.000000   36.000000     190.000000   \n",
      "max     17.000000  199.000000    122.000000   99.000000     846.000000   \n",
      "\n",
      "              BMI  Diabetes_Pedigree         Age       Class  \n",
      "count  757.000000         768.000000  768.000000  768.000000  \n",
      "mean    32.457464           0.471876   33.240885    0.348958  \n",
      "std      6.924988           0.331329   11.760232    0.476951  \n",
      "min     18.200000           0.078000   21.000000    0.000000  \n",
      "25%     27.500000           0.243750   24.000000    0.000000  \n",
      "50%     32.300000           0.372500   29.000000    0.000000  \n",
      "75%     36.600000           0.626250   41.000000    1.000000  \n",
      "max     67.100000           2.420000   81.000000    1.000000  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'https://github.com/YBI-Foundation/Dataset/raw/main/Diabetes%20Missing%20Data.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Get a statistical summary of the dataset\n",
    "summary = data.describe()\n",
    "\n",
    "# Display the summary\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6794d47c",
   "metadata": {},
   "source": [
    "#### 4. differences between data.shape and data.describe() in terms of count(given by the describe() method) and the number of columns they analyze\n",
    "\n",
    "    data.shape: the value row calculates the number of all of the rows, regardless of whether there are missing values. The value column calculates the number of all of the columns\n",
    "    \n",
    "    data.describe(): it ignores the missing values, and produce an output with the number of the rows that contains a value of the given column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b231fc33",
   "metadata": {},
   "source": [
    "#### 5. difference between attribute and method:\n",
    "\n",
    "    attribute: variables in a class\n",
    "    method: functions in a class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8089faa",
   "metadata": {},
   "source": [
    "# STA130 HW post-class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2167ec0",
   "metadata": {},
   "source": [
    "### chatbot session link: https://chatgpt.com/share/c779009b-1273-4471-887e-d75172215f2b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b29b01",
   "metadata": {},
   "source": [
    "#### summary of the session\n",
    "\n",
    "Here's a summary of our interaction, suitable for submission as part of an assignment:\n",
    "\n",
    "---\n",
    "\n",
    "**Summary of Python DataFrame Interaction**\n",
    "\n",
    "In this session, we explored several key operations and concepts related to `pandas` DataFrames in Python. \n",
    "\n",
    "1. **`df.describe()` Method**:\n",
    "   - I learned that `df.describe()` provides a statistical summary of numerical columns in a DataFrame, including metrics such as `count`, `mean`, `std`, `min`, and percentiles.\n",
    "   - Specifically, the `count` metric refers to the number of **non-null (non-NaN)** entries in each column, indicating how many valid data points exist per column. This is helpful for assessing data completeness, especially after reading from a CSV file.\n",
    "\n",
    "2. **Deleting a Column with `del df['col']`**:\n",
    "   - I was introduced to the `del` statement, which allows the removal of a column from a DataFrame. The operation `del df['col']` permanently deletes the specified column `'col'` from the DataFrame `df`.\n",
    "   - The deletion is done in place and does not return any value. This operation is useful for data cleaning or when certain columns are no longer needed for analysis.\n",
    "\n",
    "Overall, these operations are essential for managing and analyzing data effectively using `pandas`, especially in data preprocessing tasks.\n",
    "\n",
    "---\n",
    "\n",
    "This summary captures the core concepts discussed during our session."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2309f97",
   "metadata": {},
   "source": [
    "#### 6. the definition of the summary statistics:\n",
    "\n",
    "    count: the number of the non-empty entries in each column\n",
    "    \n",
    "    if there are n numerical values in the column, then\n",
    "    let x_i be the value for the i_th entry of a column, where\n",
    "    mean: x_bar = (x_1 + x_2 + ... + x_n) / n\n",
    "    std: s = sqrt(((x_1 - x_bar)^2 + (x_2 - x_bar)^2 + ... + (x_n - x_bar)^2) / (n - 1))\n",
    "    min: the minimum value in the column\n",
    "    25%: order the column, the value where the 25% of the data falls\n",
    "    50%: order the column, the value where the 50% of the data falls\n",
    "    75%: order the column, the value where the 75% of the data falls\n",
    "    max: the maximum value in the column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ca7b08",
   "metadata": {},
   "source": [
    "#### 7. question about `df.dropna()` and `del df['col']`\n",
    "    \n",
    "    df.dropna(): drop the rows where there contains aat least one empty entry\n",
    "    del df['col']: deletes the entire column \"col\"\n",
    "    \n",
    "    1. In the dataset given above, there are missing values in the \"BMI\" column. If we use \"del df['BMI']\", the entire \"BMI\" column will be deleted. However, we still need the rest of the data in the column. In this case, we do \"df.cropna()\" instead, where it only deletes the rows where there are missing values. We can still get the rest of the data. Since the number of the missing values are small compared to the whole dataset, it's fine to delete them.\n",
    "    \n",
    "    2. If there is one column where there are too many missing data, deleteing the rows of the missing data would result in a huge loss in other columns. In this case, it's better to use \"del df['col']\".\n",
    "    \n",
    "    3. Both are a way to delete the invalid data in order to make the data managable. However, as stated in above, if we use \"del df[col']\" first, it would delete the column that contains many missing data, which we would lose less data when executing \"df.dropna()\".\n",
    "    \n",
    "    4. The code and explanation is presented below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef08242d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pregnant             0\n",
       "Glucose              0\n",
       "Diastolic_BP         0\n",
       "BMI                  0\n",
       "Diabetes_Pedigree    0\n",
       "Age                  0\n",
       "Class                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import copy\n",
    "\n",
    "url = 'https://github.com/YBI-Foundation/Dataset/raw/main/Diabetes%20Missing%20Data.csv'\n",
    "original_data = pd.read_csv(url)\n",
    "\n",
    "copyed_data = copy.deepcopy(original_data) # copy the original data to make sure the modifications won't affect the origninal data\n",
    "\n",
    "del copyed_data['Serum_Insulin'] # deleting the columns with too many empty data\n",
    "del copyed_data['Skin_Fold']\n",
    "\n",
    "copyed_data = copyed_data.dropna() # deleting the rows with the empty data\n",
    "\n",
    "copyed_data.isna().sum() # show there's no missing values in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "43a56cd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before: \n",
      "     Pregnant  Glucose  Diastolic_BP  Skin_Fold  Serum_Insulin   BMI  \\\n",
      "0           6    148.0          72.0       35.0            NaN  33.6   \n",
      "1           1     85.0          66.0       29.0            NaN  26.6   \n",
      "2           8    183.0          64.0        NaN            NaN  23.3   \n",
      "3           1     89.0          66.0       23.0           94.0  28.1   \n",
      "4           0    137.0          40.0       35.0          168.0  43.1   \n",
      "..        ...      ...           ...        ...            ...   ...   \n",
      "763        10    101.0          76.0       48.0          180.0  32.9   \n",
      "764         2    122.0          70.0       27.0            NaN  36.8   \n",
      "765         5    121.0          72.0       23.0          112.0  26.2   \n",
      "766         1    126.0          60.0        NaN            NaN  30.1   \n",
      "767         1     93.0          70.0       31.0            NaN  30.4   \n",
      "\n",
      "     Diabetes_Pedigree  Age  Class  \n",
      "0                0.627   50      1  \n",
      "1                0.351   31      0  \n",
      "2                0.672   32      1  \n",
      "3                0.167   21      0  \n",
      "4                2.288   33      1  \n",
      "..                 ...  ...    ...  \n",
      "763              0.171   63      0  \n",
      "764              0.340   27      0  \n",
      "765              0.245   30      0  \n",
      "766              0.349   47      1  \n",
      "767              0.315   23      0  \n",
      "\n",
      "[768 rows x 9 columns]\n",
      "\n",
      "after: \n",
      "     Pregnant  Glucose  Diastolic_BP   BMI  Diabetes_Pedigree  Age  Class\n",
      "0           6    148.0          72.0  33.6              0.627   50      1\n",
      "1           1     85.0          66.0  26.6              0.351   31      0\n",
      "2           8    183.0          64.0  23.3              0.672   32      1\n",
      "3           1     89.0          66.0  28.1              0.167   21      0\n",
      "4           0    137.0          40.0  43.1              2.288   33      1\n",
      "..        ...      ...           ...   ...                ...  ...    ...\n",
      "763        10    101.0          76.0  32.9              0.171   63      0\n",
      "764         2    122.0          70.0  36.8              0.340   27      0\n",
      "765         5    121.0          72.0  26.2              0.245   30      0\n",
      "766         1    126.0          60.0  30.1              0.349   47      1\n",
      "767         1     93.0          70.0  30.4              0.315   23      0\n",
      "\n",
      "[724 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "print(f\"before: \\n{original_data}\\n\")\n",
    "print(f\"after: \\n{copyed_data}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35aeaa4f",
   "metadata": {},
   "source": [
    "all of the missing values have been removed from the dataset. I used `del df['col']` twice to delete column \"Serum_Insulin\" and \"Skin_Fold\". These tow columns contains too many missing values(227 for Skin_Fold, 374 for Serum_Insulin), if I do `df.dropna()` first, I will lose 200+ rows of data, which is unacceptable. Hence, I delete the columns first, then execute `df.dropna()` to clear out the rest of the empty data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995b8a1a",
   "metadata": {},
   "source": [
    "#### 8. answer to the questions\n",
    "    \n",
    "    chatbot link in the last line of the cell\n",
    "    \n",
    "    For Q2: the \"group_by()\" method groups the original data into different catagories. In this case, the \"describe()\" method calculates based on the groups, rather than the original data. \n",
    "    \n",
    "    For Q3: asking chatgpt is more convenient\n",
    "    \n",
    "    Q8 session 1 link: https://chatgpt.com/share/110e71c4-b0b0-4aef-85a9-92b190002a43\n",
    "    Q8 session 2 link: https://chatgpt.com/share/0f2b1629-90f0-43d9-95a5-b68e2215759d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f388134c",
   "metadata": {},
   "source": [
    "#### summary of Q8 session one\n",
    "\n",
    "Here’s a summary of our interaction that you can use for your assignment:\n",
    "\n",
    "---\n",
    "\n",
    "In this session, I worked with a dataset of Titanic passengers to perform some initial data analysis and to understand code behavior in Python.\n",
    "\n",
    "1. **Loading and Inspecting the Dataset**: \n",
    "   I provided a link to the Titanic dataset hosted on GitHub, but due to a network issue, I uploaded the dataset manually. Using `pandas`, the dataset was successfully loaded and the structure of the dataset was inspected, revealing columns such as `survived`, `pclass`, `sex`, `age`, and others. I noted that the dataset contains missing values in some columns like `age` and `deck`.\n",
    "\n",
    "2. **Understanding Code Behavior**:\n",
    "   I asked about the behavior of the code `df.groupby(\"col1\")[\"col2\"].describe()`. The explanation provided detailed how the code groups the data by a specific column (`col1`), selects another column (`col2`), and computes summary statistics (e.g., count, mean, standard deviation, min, max) for each group. A concrete example was given with a hypothetical sales dataset to illustrate how this works in practice.\n",
    "\n",
    "This session clarified the initial steps in analyzing the Titanic dataset and understanding the functionality of group-based descriptive statistics in Python.\n",
    "\n",
    "--- \n",
    "\n",
    "This should cover the key points from our interaction for your assignment! Let me know if you'd like to add anything else."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef85304",
   "metadata": {},
   "source": [
    "#### summary of Q8 session 2\n",
    "\n",
    "Certainly! Here’s a summary of our interaction:\n",
    "\n",
    "---\n",
    "\n",
    "**Summary of Assistance with Code Issues**\n",
    "\n",
    "**Issue:**\n",
    "The user encountered several errors while working with a Pandas DataFrame in Python. The specific errors included `NameError`, `FileNotFoundError`, `SyntaxError`, `AttributeError`, and `KeyError`.\n",
    "\n",
    "**1. NameError:**\n",
    "The user initially faced a `NameError` due to the Pandas library not being imported. The error message was `name 'pd' is not defined`. This was resolved by ensuring that Pandas was imported with `import pandas as pd`.\n",
    "\n",
    "**2. FileNotFoundError:**\n",
    "Next, the user encountered a `FileNotFoundError` indicating that the file `'titanics.csv'` could not be found. The solution involved checking the file path and ensuring the file was correctly located.\n",
    "\n",
    "**3. SyntaxError:**\n",
    "The user then faced a `SyntaxError` related to an incomplete input on the line `copyed_data.isna().sum()`. This was addressed by ensuring that the line was properly formatted and completed with a `print` statement.\n",
    "\n",
    "**4. AttributeError:**\n",
    "An `AttributeError` occurred because of a typo in the method name `isne()` instead of `isna()`. This was corrected by using the proper `isna()` method to check for missing values.\n",
    "\n",
    "**5. KeyError:**\n",
    "A `KeyError` indicated that a column name `'S'` was not found. The solution involved checking the actual column names in the DataFrame and ensuring they matched the ones being referenced in the code.\n",
    "\n",
    "**6. Additional Errors:**\n",
    "Further issues included a `NameError` caused by a missing quote around the column name `'Skin_Fold'`. This was corrected by properly enclosing column names in quotes.\n",
    "\n",
    "**Resolution:**\n",
    "The code was corrected by:\n",
    "- Importing necessary libraries.\n",
    "- Verifying and correcting file paths and column names.\n",
    "- Ensuring proper syntax and method names.\n",
    "\n",
    "The final code snippet provided was:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import copy\n",
    "\n",
    "url = 'titanics.csv'\n",
    "original_data = pd.read_csv(url)\n",
    "\n",
    "copyed_data = copy.deepcopy(original_data)\n",
    "\n",
    "del copyed_data['Serum_Insulin']\n",
    "del copyed_data['Skin_Fold']\n",
    "\n",
    "copyed_data = copyed_data.dropna()\n",
    "\n",
    "print(copyed_data.isna().sum())\n",
    "```\n",
    "\n",
    "The interaction helped resolve the issues by ensuring proper library imports, file paths, and column names, and by addressing syntax and method errors.\n",
    "\n",
    "---\n",
    "\n",
    "Feel free to modify or expand on this summary as needed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2184f3a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pregnant             0\n",
       "Glucose              0\n",
       "Diastolic_BP         0\n",
       "BMI                  0\n",
       "Diabetes_Pedigree    0\n",
       "Age                  0\n",
       "Class                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the code used for error making for Q3\n",
    "\n",
    "import pandas as pd\n",
    "import copy\n",
    "\n",
    "url = 'https://github.com/YBI-Foundation/Dataset/raw/main/Diabetes%20Missing%20Data.csv'\n",
    "original_data = pd.read_csv(url)\n",
    "\n",
    "copyed_data = copy.deepcopy(original_data) # copy the original data to make sure the modifications won't affect the origninal data\n",
    "\n",
    "del copyed_data['Serum_Insulin'] # deleting the columns with too many empty data\n",
    "del copyed_data['Skin_Fold']\n",
    "\n",
    "copyed_data = copyed_data.dropna() # deleting the rows with the empty data\n",
    "\n",
    "copyed_data.isna().sum() # show there's no missing values in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd2b484",
   "metadata": {},
   "source": [
    "#### 9. yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05195551",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
